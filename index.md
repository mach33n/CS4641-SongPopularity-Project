# CS 4641 Project
Spotify is a media streaming platform that allows users to listen to upwards of 60 million songs. Spotify provides users with information about songs like music genre, song length, artist, album. By tallying the number of individual streams of a song (or any piece of media), Spotify also provides users (and artists) with a metric of how popular a song is. Behind the scenes, Spotify keeps track of features of songs including modality, “danceability, energy, and tone. We have reason to believe that these features created by spotify are capable of predicting some level of popularity amongst other song titles with similar features. We have examples of analysing these sorts of features to support us [1,4]. 

# Problem Statement
Spotify has been an ever improving platform for a while now and currently holds the top spot among audio streaming platforms. Many artists recognize the importance of such a platform and have been utilizing the platform even more to attract listeners and build fanbases. 
Given that Spotify measures a large variety of information about the songs on its platform, we intend to investigate how the relationships between these features, both front-facing and not, interweave to affect the popularity of music upon release by predicting the popularity of a song given certain features. These predictive capabilities would be useful for artists and labels looking to optimize their music outputs in an effective way [1]. Though some other sources exist that have intended to achieve a similar goal, we hope to use a combination of unsupervised and supervised learning to achieve a more optimal and accurate analysis.

# Data Collection
A single Kaggle dataset was used throughout the course of this project midpoint [5]. All steps taken to ensure the data set be properly cleaned and prepared for any machine learning algorithms were taken with respect to how they would assist in solving our problem. The first step taken was to read in our data set as a csv and ensure all data types were properly assigned to each feature. Seeing as the label of choice(popularity), was pre-recorded in a range of 0-100, it was left as an integer though considerations were made as to turning it into a floating point probability. This was decided against as chosen algorithms were likely to be supervised regressions and having that range would be more presentable in some graphs. After assigning types, string metrics such as artist name were modified to remove extraneous characters(i.e., brackets, commas, etc). Numeric features with odd units were changed to simpler units(e.g., duration_ms was converted to duration_sec), and release dates were cleaned to just include the year. Once complete, feature importance received its first considerations with respect to the problem definition. Most data columns provided numeric data of hardly identifiable metrics provided by spotify’s API so those were left in the data as there was no reason to consider them useless with the exception of a release-date column which was deemed not very useful in its form therefore it was dropped. Columns of text such as id and song name were removed as they provided no real significance in predicting song popularity. The artist name column was removed as well however it was noted that this feature should be kept around as it could be used to generate more features via third-party APIs such as Chartmetric. With these columns removed, re-analysis of numeric columns took place and it was decided that data instances containing song durations of over 20 minutes(1200sec) should be removed as they will skew the data unfavorably(based on some histogram analysis and group discussion). In addition, the categorical feature representing the key of each song was converted to be one-hot encoded as the song keys were independent in their effect on individual songs and how they affect listening experience. After making these higher level decisions, lower level analysis in the form of histograms, correlation matrices and scatter plots occurred. It was noticed that a numerical feature “instrumentalness” had a large skew towards 0 represented in the data set which gave cause to believe this value was not recorded effectively in the initial acquisition and for that reason should be dropped. Analysis of all other numerical features displayed reasonable distributions with the exception of our chosen label, popularity. There was a similarly large presence of songs with 0 popularity which could be the result of skewed song selection by year or some other data input error but understandably this data is necessary for solving the defined problem therefore it was decided that any further analysis should be halted while this data was split into even sections as it would be in a training/testing data split. The thought process was that, if this data was sectioned evenly with regard to popularity and then analysed for correlations then model results would be more accurate when testing and hopefully equally as accurate when provided new data. In order to split this data evenly with respect to our label, a categorical feature was created using a quantile-based discretization function which created 4 bins of data with respect to popularity. After generating these bins, a stratified shuffle sampling was used to ensure even splits of data occurred with respect to each bin based on a test size ratio of 0.2. To verify this data was evenly split, we printed out the percentage of presence from each popularity bin in our training data and the total data which displayed results that were equal to the 3rd decimal place! After splitting this data, the test set was put aside and further analysis occurred on the training set. Through the use of pearson’s correlation matrix it was discovered that some features which did not have a strong correlation with popularity had a strong correlation with other features.

<img src="images/heatmap.png" alt="pearson correlation heatmap" class="center" style="width: 480px; height: 360px; margin-left: auto; margin-right: auto; display: block;"/>

4 of these instances were analyzed and through the use of some experimental testing, 3 of these instances produced extra features with above 24% correlation to popularity which was very exciting to see. Most of the initially provided features lacked much description and any unit input therefore they are not easily justifiable as to the relationships discovered in them though they were added with the hope hidden trends would be revealed. This would conclude the data exploration and cleaning phase.

# Methods
Spotify’s metrics give us unique insight into how songs are distributed with respect to traits like “danceability” and “acousticness” which are difficult to directly quantify [2]. Our first task will be to make sense of how these traits relate to each other and how they inform a song’s popularity and genre classification. We intend to plot the dataset using a variety of methods, from simple covariance metrics to see which attributes are related to each other to unsupervised clustering based on algorithms like DBSCAN to see what natural groups the songs fall into [3]. With this information we can hopefully get an idea of which features are more relevant to our task and how they relate to each other. In order to build a classifier to predict whether a song will be popular or we will create a cutoff for the “popularity” dataset and divide the training examples into “popular” and “not popular” classes. We will then train multiple models to see whether we can create a reliable predictor. As a starting point we will train a basic dense neural network with Keras as well as a decision tree model. This should give us a good idea of how different types of algorithms respond to the data. We can pick the more promising approach and tune the hyperparameters to produce an optimized model for popularity prediction. 

# Potential Results
With our model, we hope to measure the chance of a song becoming popular based on attributes of the song such as its danceability, energy, and tempo found in the database we'll be using. By first determining which attributes are the most important when determining the popularity of a song, the model can then determine if a inputted song has the perfect combination of features, predicting whether a song will likely be remembered as a bop or gather dust in the cloud.

# Discussion
Our chosen datasets are not bound to cover the same range of songs so it is highly likely that we will have to acquire additional data from the respective APIs to have a consistent set of songs that we can evaluate metrics on. Sanitizing the datasets will be important given the ratio of popular to unpopular songs is not equal. Expanding on the issue of popularity, the datasets will likely contain songs that do not equally have a balance of metrics (we expect more songs from the “pop” genre etc.) and in the process of scraping more songs, we need to balance our dataset. 


# References
[1] http://cs229.stanford.edu/proj2015/140_report.pdf 

[2] https://github.com/MattD82/Predicting-Spotify-Song-Popularity

[3] https://dl.acm.org/doi/pdf/10.1145/3068335 

[4] https://arxiv.org/pdf/1908.08609.pdf 

[5] https://www.kaggle.com/yamaerenay/spotify-dataset-19212020-160k-tracks



